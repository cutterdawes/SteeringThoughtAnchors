{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe91ebce",
   "metadata": {},
   "source": [
    "# Chunk Activation UMAP (2D/3D)\n",
    "\n",
    "Loads per-chunk mean activation vectors from `steering_anchors_{model}.json`, loads TA-style chunk categories, and plots UMAP projections color-coded by category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d363fbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, math, random, gc\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Disable Numba JIT to avoid nopython pow bug in some envs\n",
    "os.environ.setdefault('NUMBA_DISABLE_JIT', '1')\n",
    "try:\n",
    "    import numba\n",
    "    numba.config.DISABLE_JIT = True\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Try UMAP; fallback to sklearn if unavailable\n",
    "try:\n",
    "    import umap\n",
    "    HAVE_UMAP = True\n",
    "except Exception:\n",
    "    HAVE_UMAP = False\n",
    "    from sklearn.decomposition import PCA\n",
    "    from sklearn.manifold import TSNE\n",
    "\n",
    "# Resolve repo root (same pattern as other notebooks)\n",
    "repo_root = Path.cwd().resolve().parents[0] if (Path.cwd()).exists() else Path.cwd().resolve()\n",
    "repo_root\n",
    "\n",
    "import sys\n",
    "sys.path.append(str(repo_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77c635f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PosixPath('/home/cutterdawes/SteeringThoughtAnchors/generated_data/steering_anchors_deepseek-ai-DeepSeek-R1-Distill-Qwen-1.5B.json'),\n",
       " PosixPath('/home/cutterdawes/SteeringThoughtAnchors/generated_data/chunk_categories_deepseek-ai-DeepSeek-R1-Distill-Qwen-1.5B.json'),\n",
       " PosixPath('/home/cutterdawes/SteeringThoughtAnchors/generated_data/generated_data_deepseek-ai-DeepSeek-R1-Distill-Qwen-1.5B.json'))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Config\n",
    "model_name = 'deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B'\n",
    "model_tag = model_name.replace('/', '-')\n",
    "anchors_path = repo_root / 'generated_data' / f'steering_anchors_{model_tag}.json'\n",
    "categories_path = repo_root / 'generated_data' / f'chunk_categories_{model_tag}.json'\n",
    "generated_path = repo_root / 'generated_data' / f'generated_data_{model_tag}.json'\n",
    "output_dir = repo_root / 'generated_data' / 'figures'\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "anchors_path, categories_path, generated_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c396924f",
   "metadata": {},
   "source": [
    "## Data Sources\n",
    "\n",
    "- Vectors: `steering_anchors_{model}.json` (per-chunk mean activations).\n",
    "- Categories: `chunk_categories_{model}.json` (derived from un-annotated `generated_data_{model}.json`).\n",
    "- Generated CoT: `generated_data_{model}.json` (loaded for reference and alignment).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e47d8a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 20, 20)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "with open(anchors_path, 'r') as f:\n",
    "    anchors_payload = json.load(f)\n",
    "with open(categories_path, 'r') as f:\n",
    "    cats_payload = json.load(f)\n",
    "with open(generated_path, 'r') as f:\n",
    "    generated = json.load(f)\n",
    "len(anchors_payload.get('examples', [])), len(cats_payload.get('examples', [])), len(generated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d96fa97d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No mean vectors found for deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B. You can save to generated_data/mean_vectors_deepseek-r1-distill-qwen-1.5b.pt.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model to compute per-chunk activations when anchors are missing or incomplete\n",
    "from utils import load_model_and_vectors\n",
    "model, tokenizer, _ = load_model_and_vectors(model_name=model_name, compute_features=False, device=('cuda' if __import__('torch').cuda.is_available() else ('mps' if __import__('torch').backends.mps.is_available() else 'cpu')))\n",
    "model.model.eval()\n",
    "# Choose layer for mean activations (default: last)\n",
    "try:\n",
    "    layer_idx = anchors_payload.get('layer', model.config.num_hidden_layers-1)\n",
    "except Exception:\n",
    "    layer_idx = model.config.num_hidden_layers-1\n",
    "layer_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "197103f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TA category colors (replicated)\n",
    "CATEGORY_COLORS = {\n",
    "    'Active Computation': '#34A853',\n",
    "    'Fact Retrieval': '#FBBC05',\n",
    "    'Final Answer Emission': '#795548',\n",
    "    'Plan Generation': '#EA4335',\n",
    "    'Problem Setup': '#4285F4',\n",
    "    'Result Consolidation': '#00BCD4',\n",
    "    'Self Checking': '#FF9800',\n",
    "    'Uncertainty Management': '#9C27B0'\n",
    "}\n",
    "\n",
    "def tag_to_display(tag: str) -> str:\n",
    "    # Convert snake_case to Title Case to match palette keys\n",
    "    s = (tag or 'unknown').replace('_', ' ').strip()\n",
    "    return ' '.join([w.capitalize() for w in s.split()])\n",
    "\n",
    "def pick_color(display_tag: str) -> str:\n",
    "    if not display_tag:\n",
    "        return '#9E9E9E'\n",
    "    return CATEGORY_COLORS.get(display_tag, '#9E9E9E')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77f0b4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build dataset: X = vectors, y = display_tag, meta = (example, chunk)\n",
    "# Prefer cached anchors vectors if available for an example; otherwise compute on-the-fly from generated data.\n",
    "import numpy as np\n",
    "from experiments.find_steering_anchors import compute_chunk_vectors_for_example\n",
    "X = []; Y = []; META = []\n",
    "examples_cats = cats_payload.get('examples', [])\n",
    "cat_by_idx = {e.get('example_index', i): e for i, e in enumerate(examples_cats)}\n",
    "# Map example_index -> {chunk_index: vector} from anchors (if present)\n",
    "anchors_map = {}\n",
    "for ex_i, aex in enumerate(anchors_payload.get('examples', [])):\n",
    "    anchors_map[ex_i] = {int(ch.get('chunk_index',0)): ch.get('vector', []) for ch in aex.get('chunks', [])}\n",
    "\n",
    "for ex_i, ex in enumerate(generated):\n",
    "    # Split chunks\n",
    "    try:\n",
    "        from utils import split_solution_into_chunks\n",
    "        chunks = split_solution_into_chunks(ex.get('cot') or '')\n",
    "    except Exception:\n",
    "        import re\n",
    "        chunks = [p.strip() for p in re.split(r'(?<=[\\.\\!\\?])\\s+|\\n\\n+', ex.get('cot') or '') if p.strip()]\n",
    "    if not chunks:\n",
    "        continue\n",
    "    # Categories for this example\n",
    "    cat_entry = cat_by_idx.get(ex_i, {})\n",
    "    cat_map = cat_entry.get('categories', {})\n",
    "    # Use cached vectors if complete; else compute\n",
    "    have_all = ex_i in anchors_map and len(anchors_map[ex_i]) >= len(chunks)\n",
    "    if have_all:\n",
    "        for idx in range(len(chunks)):\n",
    "            vec = anchors_map[ex_i].get(idx, [])\n",
    "            if not vec:\n",
    "                continue\n",
    "            tags = cat_map.get(str(idx), {}).get('function_tags', ['unknown'])\n",
    "            disp = ' '.join([w.capitalize() for w in (tags[0] if tags else 'unknown').replace('_',' ').split()])\n",
    "            X.append(vec); Y.append(disp); META.append((ex_i, idx))\n",
    "    else:\n",
    "        # Compute vectors for this example\n",
    "        res = compute_chunk_vectors_for_example(model, tokenizer, ex, layer_idx=layer_idx, device=('cuda' if __import__('torch').cuda.is_available() else ('mps' if __import__('torch').backends.mps.is_available() else 'cpu')))\n",
    "        if not res:\n",
    "            continue\n",
    "        vec_by_idx = {int(ch['chunk_index']): ch['vector'] for ch in res.get('chunks', []) if ch.get('vector')}\n",
    "        for idx in range(len(chunks)):\n",
    "            vec = vec_by_idx.get(idx, None)\n",
    "            if vec is None:\n",
    "                continue\n",
    "            tags = cat_map.get(str(idx), {}).get('function_tags', ['unknown'])\n",
    "            disp = ' '.join([w.capitalize() for w in (tags[0] if tags else 'unknown').replace('_',' ').split()])\n",
    "            X.append(vec); Y.append(disp); META.append((ex_i, idx))\n",
    "X = np.asarray(X, dtype=np.float32); len(X), len(Y), len(META)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2f6d1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "X_np = np.asarray(X, dtype=np.float32)\n",
    "n_samples, n_dims = (X_np.shape[0] if X_np.ndim>0 else 0), (X_np.shape[1] if X_np.ndim==2 else 0)\n",
    "\n",
    "def umap_2d_with_fallbacks(X_np):\n",
    "    # Edge cases: too few samples/dims → PCA with min dims\n",
    "    from sklearn.decomposition import PCA\n",
    "    if X_np.ndim != 2 or X_np.shape[0] < 3 or X_np.shape[1] < 2:\n",
    "        k = 2 if X_np.ndim==2 and X_np.shape[1] >= 2 else 1\n",
    "        warnings.warn('Too few samples/dims for UMAP; using PCA')\n",
    "        return PCA(n_components=k, random_state=42).fit_transform(X_np), f'PCA({k}D)'\n",
    "    # Try UMAP (cosine) → UMAP (cosine, JIT disabled) → UMAP (precomputed) → PCA\n",
    "    try:\n",
    "        reducer = umap.UMAP(n_components=2, random_state=42, metric='cosine')\n",
    "        return reducer.fit_transform(X_np), \"UMAP(cosine)\"\n",
    "    except Exception as e:\n",
    "        print(\"UMAP(cosine) failed:\", e)\n",
    "    try:\n",
    "        import numba\n",
    "        numba.config.DISABLE_JIT = True\n",
    "        reducer = umap.UMAP(n_components=2, random_state=42, metric='cosine')\n",
    "        out = reducer.fit_transform(X_np)\n",
    "        print(\"Recovered with numba JIT disabled.\")\n",
    "        return out, \"UMAP(cosine, JIT disabled)\"\n",
    "    except Exception as e:\n",
    "        print(\"UMAP(cosine, JIT disabled) failed:\", e)\n",
    "    try:\n",
    "        from sklearn.metrics import pairwise_distances\n",
    "        D = pairwise_distances(X_np, metric='cosine')\n",
    "        reducer = umap.UMAP(n_components=2, random_state=42, metric='precomputed')\n",
    "        out = reducer.fit_transform(D)\n",
    "        print(\"Recovered with precomputed cosine distances.\")\n",
    "        return out, \"UMAP(precomputed cosine)\"\n",
    "    except Exception as e:\n",
    "        print(\"UMAP(precomputed) failed:\", e)\n",
    "    print(\"Falling back to PCA(2D).\")\n",
    "    return PCA(n_components=2, random_state=42).fit_transform(X_np), \"PCA(2D)\"\n",
    "\n",
    "if HAVE_UMAP:\n",
    "    X2, method2 = umap_2d_with_fallbacks(X_np)\n",
    "else:\n",
    "    from sklearn.decomposition import PCA\n",
    "    X2, method2 = PCA(n_components=min(2, max(1, n_dims)), random_state=42).fit_transform(X_np), f'PCA({min(2, max(1, n_dims))}D)'\n",
    "\n",
    "plt.figure(figsize=(7,6))\n",
    "for cls in sorted(set(Y)):\n",
    "    mask = np.array([y == cls for y in Y])\n",
    "    color = pick_color(cls)\n",
    "    plt.scatter(X2[mask,0], X2[mask,1], s=12, alpha=0.6, c=color, label=cls)\n",
    "plt.legend(markerscale=2, fontsize=9, ncol=2)\n",
    "plt.title(f'Chunk activations: {method2}')\n",
    "plt.xlabel('dim 1'); plt.ylabel('dim 2')\n",
    "plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6cf8f21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401\n",
    "import warnings\n",
    "\n",
    "# Ensure numpy array\n",
    "X_np = np.asarray(X, dtype=np.float32)\n",
    "n_samples, n_dims = (X_np.shape[0] if X_np.ndim>0 else 0), (X_np.shape[1] if X_np.ndim==2 else 0)\n",
    "\n",
    "# Normalize vectors so euclidean ~= cosine (monotonic) on unit sphere\n",
    "norms = (np.linalg.norm(X_np, axis=1, keepdims=True) + 1e-12) if n_samples>0 else 1.0\n",
    "X_unit = X_np / norms\n",
    "\n",
    "def embedding_3d_with_fallbacks(X_unit):\n",
    "    # Edge cases: too few samples/dims → PCA with min dims\n",
    "    from sklearn.decomposition import PCA\n",
    "    if X_unit.ndim != 2 or X_unit.shape[0] < 5 or X_unit.shape[1] < 3:\n",
    "        k = min(3, max(1, X_unit.shape[1] if X_unit.ndim==2 else 1))\n",
    "        warnings.warn('Too few samples/dims for UMAP/TSNE; using PCA')\n",
    "        return PCA(n_components=k, random_state=42).fit_transform(X_unit), f'PCA({k}D)'\n",
    "    # 1) Prefer UMAP with Euclidean (robust; avoids numba cosine path)\n",
    "    if HAVE_UMAP:\n",
    "        try:\n",
    "            reducer = umap.UMAP(n_components=3, random_state=42, metric='euclidean')\n",
    "            out = reducer.fit_transform(X_unit)\n",
    "            return out, \"UMAP(euclidean, 3D)\"\n",
    "        except Exception as e:\n",
    "            print(\"UMAP(euclidean, 3D) failed:\", e)\n",
    "        # 2) Try precomputed cosine distances\n",
    "        try:\n",
    "            from sklearn.metrics import pairwise_distances\n",
    "            D = pairwise_distances(X_unit, metric='cosine')\n",
    "            reducer = umap.UMAP(n_components=3, random_state=42, metric='precomputed')\n",
    "            out = reducer.fit_transform(D)\n",
    "            print(\"Recovered with precomputed cosine distances.\")\n",
    "            return out, \"UMAP(precomputed cosine, 3D)\"\n",
    "        except Exception as e:\n",
    "            print(\"UMAP(precomputed, 3D) failed:\", e)\n",
    "    # 3) Fall back to t-SNE (safe perplexity), then PCA\n",
    "    try:\n",
    "        from sklearn.manifold import TSNE\n",
    "        # Ensure perplexity < n_samples and at least 2\n",
    "        perp = max(2, min(30, X_unit.shape[0]//3))\n",
    "        out = TSNE(n_components=3, random_state=42, init='pca', learning_rate='auto', perplexity=perp).fit_transform(X_unit)\n",
    "        return out, \"TSNE(3D)\"\n",
    "    except Exception as e:\n",
    "        print(\"TSNE(3D) failed:\", e)\n",
    "        from sklearn.decomposition import PCA\n",
    "        out = PCA(n_components=min(3, max(1, X_unit.shape[1])), random_state=42).fit_transform(X_unit)\n",
    "        return out, f'PCA({min(3, max(1, X_unit.shape[1]))}D)'\n",
    "\n",
    "X3, method3 = embedding_3d_with_fallbacks(X_unit)\n",
    "\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "for cls in sorted(set(Y)):\n",
    "    mask = np.array([y == cls for y in Y])\n",
    "    color = pick_color(cls)\n",
    "    ax.scatter(X3[mask,0], X3[mask,1], X3[mask,2], s=10, alpha=0.45, c=color, label=cls)\n",
    "ax.set_title(f'Chunk activations: {method3}')\n",
    "ax.set_xlabel('dim 1'); ax.set_ylabel('dim 2'); ax.set_zlabel('dim 3')\n",
    "plt.legend(markerscale=2, fontsize=9, ncol=2)\n",
    "plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c6f4509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print each chunk alongside its category (for manual inspection)\n",
    "for (ex_i, ch_i), cat in zip(META, Y):\n",
    "    ex = examples_anchors[ex_i]\n",
    "    chunks = ex.get('chunks', [])\n",
    "    chunk = next((c for c in chunks if int(c.get('chunk_index', -1)) == ch_i), None)\n",
    "    text = chunk.get('text', '').strip() if chunk else ''\n",
    "    print(f'Example {ex_i} Chunk {ch_i} [{cat}]:\\n{text}\\n{\"-\"*40}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219abb6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anchorsteering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "steering_fixes": {
   "umap_numba_disable": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

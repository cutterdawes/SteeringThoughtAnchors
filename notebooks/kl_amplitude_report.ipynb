{"cells": [{"cell_type": "markdown", "id": "title", "metadata": {}, "source": ["# KL Amplitude Report (per chunk)\n", "\n", "Compute the quadratic KL curve amplitude for each chunk (latent steering per-chunk vector), then print alongside counterfactual metrics: `counterfactual_importance_kl`, `counterfactual_accuracies`, `different_trajectories_fraction`, `overdeterminedness`."]}, {"cell_type": "code", "execution_count": null, "id": "setup", "metadata": {}, "outputs": [], "source": ["import os, json, math, gc, re\n", "from pathlib import Path\n", "import numpy as np\n", "import torch\n", "import matplotlib.pyplot as plt\n", "\n", "# Resolve repo root (match other notebooks)\n", "repo_root = Path.cwd().resolve().parents[0] if (Path.cwd()).exists() else Path.cwd().resolve()\n", "import sys\n", "sys.path.append(str(repo_root))\n", "\n", "# Config\n", "model_name = 'deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B'\n", "model_tag = model_name.replace('/', '-')\n", "betas = np.linspace(-10, 10, 21)  # steering amplitudes (\u00d7 RMS)\n", "max_examples = 2  # set None for all; kept small to limit runtime\n", "\n", "# Paths\n", "annotated_path = repo_root / 'generated_data' / f'generated_data_annotated_{model_tag}.json'\n", "anchors_path = repo_root / 'generated_data' / f'steering_anchors_{model_tag}.json'\n", "\n", "# Load model/tokenizer\n", "from utils import load_model_and_vectors, split_solution_into_chunks\n", "device = 'cuda' if torch.cuda.is_available() else ('mps' if torch.backends.mps.is_available() else 'cpu')\n", "model, tokenizer, _ = load_model_and_vectors(model_name=model_name, compute_features=False, device=device)\n", "model.model.eval()\n", "\n", "# Load datasets\n", "with open(annotated_path, 'r') as f:\n", "    annotated = json.load(f)\n", "with open(anchors_path, 'r') as f:\n", "    anchors_payload = json.load(f)\n", "examples_anchors = anchors_payload.get('examples', [])\n", "len(annotated), len(examples_anchors)"]}, {"cell_type": "code", "execution_count": null, "id": "sanity-check", "metadata": {}, "outputs": [], "source": ["from pathlib import Path\n", "print('--- Sanity check ---')\n", "names = []\n", "if 'annotated_path' in globals(): names.append(('annotated_path', str(annotated_path)))\n", "if 'anchors_path' in globals(): names.append(('anchors_path', str(anchors_path)))\n", "if 'vectors_path' in globals(): names.append(('vectors_path', str(vectors_path)))\n", "all_ok = True\n", "for nm, p in names:\n", "    ok = Path(p).exists()\n", "    print(f'{nm}:', 'OK' if ok else 'MISSING', p)\n", "    all_ok = all_ok and ok\n", "try:\n", "    from utils import forward_with_logits, kl_from_logits\n", "    print('utils import: OK')\n", "except Exception as e:\n", "    print('utils import failed:', e); all_ok=False\n", "try:\n", "    import torch\n", "    dev = 'cuda' if torch.cuda.is_available() else ('mps' if torch.backends.mps.is_available() else 'cpu')\n", "    print('device:', dev)\n", "except Exception as e:\n", "    print('torch not available:', e)\n", "SANITY_OK = all_ok\n", "print('SANITY_OK =', SANITY_OK)\n"]}, {"cell_type": "code", "execution_count": null, "id": "helpers-forward", "metadata": {}, "outputs": [], "source": ["from utils import compute_kl_curve_for_chunk\n", "import numpy as np\n", "\n", "def kl_amplitude(ys: list, xs: np.ndarray) -> float:\n", "    Y = np.asarray(ys, dtype=float)\n", "    X = np.asarray(xs, dtype=float)\n", "    n = min(len(Y), len(X))\n", "    if n < 3:\n", "        return float('nan')\n", "    try:\n", "        a = float(np.polyfit(X[:n], Y[:n], 2)[0])\n", "        return abs(a)\n", "    except Exception:\n", "        return float('nan')\n"]}, {"cell_type": "code", "execution_count": null, "id": "collect-print", "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "def preview(s: str, n: int = 80) -> str:\n", "    s = (s or '').replace('\\n',' ').strip()\n", "    return (s[:n] + '...') if len(s) > n else s\n", "rows = []\n", "ex_list = annotated\n", "if max_examples is not None:\n", "    ex_list = ex_list[:int(max_examples)]\n", "for ex_i, ex in enumerate(ex_list):\n", "    if ex_i >= len(examples_anchors):\n", "        break\n", "    anchors_ex = examples_anchors[ex_i] or {}\n", "    layer_idx = anchors_ex.get('layer', model.config.num_hidden_layers - 1)\n", "    # Split chunks\n", "    try:\n", "        chunks = split_solution_into_chunks(ex.get('cot') or '')\n", "    except Exception:\n", "        chunks = [p.strip() for p in re.split(r'(?<=[\\.\\!\\?])\\s+|\\n\\n+', ex.get('cot') or '') if p.strip()]\n", "    if not chunks:\n", "        continue\n", "    # Metric arrays\n", "    m_kl = ex.get('counterfactual_importance_kl', [])\n", "    m_acc = ex.get('counterfactual_accuracies', [])\n", "    m_diff = ex.get('different_trajectories_fraction', [])\n", "    m_over = ex.get('overdeterminedness', [])\n", "    for ci in range(len(chunks)):\n", "        ys = compute_kl_curve_for_chunk(model, tokenizer, ex, anchors_ex, layer_idx=int(layer_idx), betas=betas, device=device, chunk_index=int(ci))\n", "        amp = kl_amplitude(ys, betas) if ys else float('nan')\n", "        rows.append({\n", "            'example_index': ex_i,\n", "            'chunk_index': ci,\n", "            'chunk_text': preview(chunks[ci], 90),\n", "            'kl_amplitude': amp,\n", "            'counterfactual_importance_kl': float(m_kl[ci]) if ci < len(m_kl) else float('nan'),\n", "            'counterfactual_accuracies': float(m_acc[ci]) if ci < len(m_acc) else float('nan'),\n", "            'different_trajectories_fraction': float(m_diff[ci]) if ci < len(m_diff) else float('nan'),\n", "            'overdeterminedness': float(m_over[ci]) if ci < len(m_over) else float('nan'),\n", "        })\n", "df = pd.DataFrame(rows)\n", "df_sorted = df.sort_values(['example_index','chunk_index']).reset_index(drop=True)\n", "df_sorted.head(10)\n"]}, {"cell_type": "code", "execution_count": null, "id": "printout", "metadata": {}, "outputs": [], "source": ["# Pretty print one example at a time\n", "ex_group = df_sorted.groupby('example_index')\n", "for ex_i, sub in ex_group:\n", "    print(f'\\n=== Example {int(ex_i)} ===')\n", "    for _, r in sub.iterrows():\n", "        print('[{:02d}] amp={:.4g} | KL={:.4g} | acc={:.3f} | diff={:.3f} | over={:.3f} :: {}'.format(              int(r['chunk_index']), r['kl_amplitude'], r['counterfactual_importance_kl'], r['counterfactual_accuracies'],              r['different_trajectories_fraction'], r['overdeterminedness'], r['chunk_text']))\n"]}], "metadata": {"kernelspec": {"display_name": "anchorsteering", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.10.18"}}, "nbformat": 4, "nbformat_minor": 5}